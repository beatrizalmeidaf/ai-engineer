{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisão - Image Classification\n",
    "\n",
    "Revisão focada em aprender a sintaxe e conceitos passados nessa pasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset e DataLoader \n",
    "\n",
    "Quando usamos **PyTorch**, precisamos preparar os dados antes de treinar uma rede neural. Isso pode ser demorado, mas PyTorch tem algumas ferramentas que facilitam esse processo:  \n",
    "\n",
    "1. **Dataset** → É uma \"caixa\" que guarda os dados. Podemos acessar qualquer dado individualmente dentro dela.  \n",
    "2. **Data Loader** → Pega os dados do Dataset e manda para a rede neural. Ele pode definir quantos dados serão enviados por vez e quantos processos vão trabalhar ao mesmo tempo.  \n",
    "\n",
    "---\n",
    "\n",
    "### Criando um Dataset  \n",
    "Para que o PyTorch consiga trabalhar com qualquer tipo de dado (imagem, áudio, texto, etc.), ele precisa seguir um padrão simples:  \n",
    "\n",
    "- Ter um método que retorna o **tamanho do dataset**.  \n",
    "- Ter um método que retorna **um item específico** do dataset (como uma imagem e seu rótulo).  \n",
    "\n",
    "Isso é útil, mas pode ser trabalhoso. Então, PyTorch já oferece ferramentas prontas!  \n",
    "\n",
    "---\n",
    "\n",
    "### **Torchvision**   \n",
    "Se estamos lidando com **imagens**, o PyTorch tem o `ImageFolder`, que organiza as imagens automaticamente. Basta colocar as imagens em pastas com o nome da categoria. Exemplo:  \n",
    "\n",
    "```\n",
    "/train  \n",
    " ├── cat/ (todas as imagens de gatos)  \n",
    " ├── fish/ (todas as imagens de peixes)  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "train_data_path = \"./train/\"\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=train_data_path, transform = transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Por que fazemos essas transformações?**  \n",
    "**Redimensionamento** → Para que todas as imagens tenham o mesmo tamanho (64x64) e o processamento seja mais rápido.  \n",
    "**Conversão para Tensor** → Para que o PyTorch possa trabalhar com os dados.  \n",
    "**Normalização** → Para manter os valores entre 0 e 1, evitando que fiquem muito grandes e atrapalhem o aprendizado da rede neural.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_path = \"./val/\"\n",
    "val_data = torchvision.datasets.ImageFolder(root=val_data_path, transform = transforms)\n",
    "\n",
    "test_data_path = \"./test/\"\n",
    "test_data = torchvision.datasets.ImageFolder(root=test_data_path, transform=transforms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de Treinamento  \n",
    "Usado na fase de treinamento para atualizar o modelo.  \n",
    "\n",
    "### Conjunto de Validação  \n",
    "Usado para avaliar como o modelo está generalizando para o domínio do problema, em vez de apenas se ajustar aos dados de treinamento; não é usado para atualizar o modelo diretamente.  \n",
    "\n",
    "### Conjunto de Teste  \n",
    "Um conjunto de dados final que fornece uma avaliação definitiva do desempenho do modelo após a conclusão do treinamento.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_data_loader = data.DataLoader(train_data, batch_size)\n",
    "val_data_loader = data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_data_loader = data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__\n",
    "        self.fc1 = nn.Linear(12288, 84)\n",
    "        self.fc2 = nn.Linear(84, 50)\n",
    "        self.fc3 = nn.Linear(50, 2)\n",
    "\n",
    "    def forward(self):\n",
    "        x = x.view(-1, 12288) # achata imagem para um vetor 1D\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) # a crossentropy ja vai aplicar o softmax\n",
    "        return x\n",
    "    \n",
    "simplenet = SimpleNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Perda no PyTorch\n",
    "\n",
    "O PyTorch já vem com várias funções de perda prontas para diferentes tipos de problemas. Nesse caso estamos lidando com classificação multiclasse, então usamos CrossEntropyLoss\n",
    "\n",
    "O CrossEntropyLoss já aplica a função Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimizador\n",
    "\n",
    "Um otimizador ajusta os pesos da rede para que a função de perda seja minimizada. Ele faz isso calculando gradientes e alterando os pesos na direção certa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optim.Adam(simplenet.parameters(), lr=0.001) # passa os pesos da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "simplenet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, label in train_loader:\n",
    "    output = simplenet(data)              # passa os dados pela rede\n",
    "    loss = criterion(output, label)       # calcula a perda\n",
    "    optimizer.zero_grad()                 # zera os gradientes anteriores\n",
    "    loss.backward()                       # calcula os gradientes\n",
    "    optimizer.step()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ou fazer de forma mais robusta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item()\n",
    "        \n",
    "        training_loss /= len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs, targets = batch\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                output = model(inputs)\n",
    "                loss = loss_fn(output, targets)\n",
    "                valid_loss += loss.data.item()\n",
    "                \n",
    "                correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
    "                num_correct += torch.sum(correct).item()\n",
    "                num_examples += correct.shape[0]\n",
    "        \n",
    "        valid_loss /= len(val_loader)\n",
    "        accuracy = num_correct / num_examples\n",
    "        \n",
    "        print(f'Epoch: {epoch}, Training Loss: {training_loss:.2f}, Validation Loss: {valid_loss:.2f}, Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(simplenet, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, test_data_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "labels = ['cat', 'fish']\n",
    "img = Image.open(FILENAME)\n",
    "img = to_tensor(img)\n",
    "img = img.unsqueeze(0)  # adiciona uma dimensão extra para criar um \"batch\" de tamanho 1\n",
    "\n",
    "prediction = simplenet(img)\n",
    "prediction = prediction.argmax()\n",
    "print(labels[prediction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
