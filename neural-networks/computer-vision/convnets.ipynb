{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b58f60",
   "metadata": {},
   "source": [
    "### Diferença entre Camadas Densas e Convolucionais\n",
    "\n",
    "- **Camadas Densas (Fully Connected):**\n",
    "  - Aprendem **padrões globais** nos dados de entrada.\n",
    "  - Exemplo: no MNIST, analisam todos os pixels ao mesmo tempo.\n",
    "\n",
    "- **Camadas Convolucionais:**\n",
    "  - Aprendem **padrões locais** observando pequenas janelas da entrada.\n",
    "  - Exemplo: identificam padrões em regiões 3×3 de uma imagem.\n",
    "\n",
    "Camadas convolucionais são mais eficientes para dados espaciais como imagens, pois focam em pequenas partes da entrada de cada vez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409272aa",
   "metadata": {},
   "source": [
    "### Propriedades Interessantes das Redes Convolucionais (ConvNets)\n",
    "\n",
    "1. **Invariância à Translação:**\n",
    "   - Após aprender um padrão em uma parte da imagem (ex: canto inferior direito), a rede pode reconhecê-lo em qualquer outro lugar (ex: canto superior esquerdo).\n",
    "   - Isso torna as convnets mais **eficientes com dados**, pois precisam de **menos exemplos** para generalizar bem.\n",
    "   - Redes densas teriam que reaprender o mesmo padrão em cada nova posição.\n",
    "\n",
    "2. **Hierarquia Espacial de Padrões:**\n",
    "   - **Primeiras camadas convolucionais** aprendem padrões simples (ex: bordas).\n",
    "   - **Camadas intermediárias** aprendem combinações desses padrões simples (ex: formas).\n",
    "   - **Camadas mais profundas** aprendem conceitos visuais mais complexos (ex: rostos, objetos).\n",
    "   - Isso reflete a estrutura **hierárquica e espacial** do mundo visual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ae558",
   "metadata": {},
   "source": [
    "### Como Funciona a Operação de Convolução\n",
    "\n",
    "- Convoluções atuam sobre **tensores de rank 3** chamados **mapas de características (feature maps)**:\n",
    "  - Possuem 2 eixos espaciais: **altura** e **largura**.\n",
    "  - E 1 eixo de profundidade (**channels**):\n",
    "    - Imagens RGB: profundidade = 3 (vermelho, verde e azul).\n",
    "    - Imagens em preto e branco (ex: MNIST): profundidade = 1 (tons de cinza).\n",
    "\n",
    "- A convolução:\n",
    "  - Extrai **pequenos blocos (patches)** da entrada e aplica a **mesma transformação** em todos.\n",
    "  - Gera um novo **mapa de características de saída**, também um tensor de rank 3.\n",
    "\n",
    "- A profundidade da **saída** é definida pelo número de **filtros** na camada:\n",
    "  - Cada filtro aprende a detectar um **padrão específico** nos dados.\n",
    "  - Ex: um filtro pode detectar bordas, outro pode detectar curvas, outro pode representar algo mais abstrato, como \"presença de um rosto\".\n",
    "\n",
    "- **Exemplo (MNIST):**\n",
    "  - Entrada: mapa (28, 28, 1).\n",
    "  - Saída após 1ª convolução: mapa (26, 26, 32).\n",
    "    - 32 filtros aplicados → 32 canais de saída.\n",
    "    - Cada canal contém uma **resposta do filtro** ao longo da imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36720f06",
   "metadata": {},
   "source": [
    "### Entendendo Feature Maps e Parâmetros de Convolução\n",
    "\n",
    "- **Feature Map** (Mapa de Características):\n",
    "  - Cada **dimensão do eixo de profundidade** representa um **filtro** (ou \"feature\").\n",
    "  - O tensor bidimensional `output[:, :, n]` representa um **mapa de resposta** do filtro `n`, indicando onde esse padrão aparece na imagem.\n",
    "\n",
    "- **Parâmetros principais de uma convolução:**\n",
    "  1. **Tamanho da Janela (Patch):**\n",
    "     - Define o tamanho do bloco extraído da imagem.\n",
    "     - Exemplo comum: **3×3** ou **5×5**.\n",
    "  2. **Profundidade da Saída:**\n",
    "     - Define o número de **filtros** aplicados.\n",
    "     - Exemplo: `Conv2D(32, (3, 3))` aplica 32 filtros 3×3 → saída com profundidade 32.\n",
    "\n",
    "- **Como a convolução funciona:**\n",
    "  - A janela 3D (ex: 3×3×input_depth) é **deslizada** pela imagem de entrada.\n",
    "  - Em cada posição, um **patch** é extraído e transformado em um **vetor 1D** (tamanho = número de filtros).\n",
    "  - Isso é feito por um **produto tensorial** com pesos aprendidos chamados **kernel**.\n",
    "  - O **mesmo kernel** é usado em todas as posições (compartilhamento de pesos).\n",
    "  - O resultado final é um **novo tensor 3D**, onde:\n",
    "    - Cada posição `(i, j, :)` da saída corresponde ao patch centralizado em `(i, j)` da entrada.\n",
    "    - Cada canal da saída indica a **intensidade da resposta** de um filtro naquela posição.\n",
    "\n",
    "- **Resumo Visual:**\n",
    "  - Entrada: `(altura, largura, profundidade)`\n",
    "  - Janela: `(3, 3, profundidade)`\n",
    "  - Saída: `(nova_altura, nova_largura, número_de_filtros)`\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "1999a68f",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f03a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e1d24",
   "metadata": {},
   "source": [
    "## Lembrete:\n",
    "\n",
    "- Camadas de MaxPooling reduzem a dimensionalidade\n",
    "  - Serve para **reduzir a altura e a largura** dos mapas de características (feature maps).\n",
    "  - Exemplo: uma imagem de entrada 26×26 pode virar 13×13 após o `MaxPooling2D`.\n",
    "\n",
    "- **Como funciona?**\n",
    "  - Em vez de aplicar filtros aprendidos como na convolução, o max pooling aplica uma **operação fixa de máximo** em janelas da imagem.\n",
    "  - Normalmente usa-se janelas de **2×2 com stride 2**, o que significa que a janela se move de 2 em 2 pixels e captura o **maior valor** dentro dela.\n",
    "  - Isso reduz a imagem pela metade em cada dimensão (altura e largura).\n",
    "\n",
    "- **Por que usar Max Pooling?**\n",
    "  - **Reduz o custo computacional**, diminuindo o número de parâmetros e operações.\n",
    "  - **Torna os padrões mais robustos** a pequenas mudanças (translações) na posição dos objetos.\n",
    "  - Ajuda a rede a **focar nas características mais importantes** da imagem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7389c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fffb8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,530</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m11,530\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,202</span> (407.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,202\u001b[0m (407.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,202</span> (407.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m104,202\u001b[0m (407.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5d3d080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - accuracy: 0.8823 - loss: 0.3698\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - accuracy: 0.9855 - loss: 0.0479\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 20ms/step - accuracy: 0.9908 - loss: 0.0311\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 28ms/step - accuracy: 0.9935 - loss: 0.0228\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 16ms/step - accuracy: 0.9953 - loss: 0.0168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16234d99f70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "335d4b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9898 - loss: 0.0331\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3970612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.992\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84dee6a",
   "metadata": {},
   "source": [
    "### Fine-Tuning de um Modelo Pré-Treinado\n",
    "\n",
    "**O que é Fine-Tuning?**\n",
    "- É uma técnica usada para **ajustar finamente** os pesos de um modelo pré-treinado, tornando-o mais específico para um novo problema.\n",
    "- Consiste em **descongelar (unfreeze)** algumas das últimas camadas do modelo base e **treiná-las junto com a nova parte adicionada**, geralmente um classificador denso.\n",
    "\n",
    "**Quando usar Fine-Tuning?**\n",
    "- Depois de treinar um classificador personalizado sobre um modelo congelado.\n",
    "- Útil quando temos um conjunto de dados menor, mas queremos aproveitar representações aprendidas de um modelo robusto como o **VGG16**.\n",
    "\n",
    "**Por que não descongelar tudo desde o início?**\n",
    "- Porque os gradientes gerados pelo classificador ainda não treinado são grandes e **podem destruir as representações úteis** aprendidas pelas camadas convolucionais.\n",
    "\n",
    "\n",
    "### Passos para Fazer Fine-Tuning\n",
    "\n",
    "1. **Adicionar** uma rede personalizada (ex: um classificador denso) no topo de um modelo base já treinado.\n",
    "2. **Congelar o modelo base** (não permitir o ajuste de seus pesos).\n",
    "3. **Treinar apenas o classificador adicionado.**\n",
    "4. **Descongelar algumas camadas superiores** do modelo base (deixar que seus pesos possam ser ajustados).\n",
    "   - **Não descongelar camadas de _Batch Normalization_**, pois isso pode prejudicar a estabilidade do treinamento.\n",
    "5. **Treinar novamente**, agora ajustando tanto as camadas descongeladas do modelo base quanto o classificador.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redes-neurais",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
