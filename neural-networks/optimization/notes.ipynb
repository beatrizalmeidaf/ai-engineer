{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "597fa46a",
   "metadata": {},
   "source": [
    "# Otimizações para Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec95170",
   "metadata": {},
   "source": [
    "## O que são hiperparâmetros?\n",
    "\n",
    "* Decisões de projeto do modelo: número de camadas, unidades, ativação (`relu`, etc), uso de `Dropout`, `BatchNormalization`, etc.\n",
    "* Não são aprendidos via backpropagation, são definidos manualmente ou por busca automatizada.\n",
    "\n",
    "## Como funciona a otimização:\n",
    "\n",
    "1. Escolha automática de hiperparâmetros.\n",
    "2. Treinamento do modelo com esses hiperparâmetros.\n",
    "3. Avaliação em dados de validação.\n",
    "4. Escolha do próximo conjunto de hiperparâmetros com base nos resultados anteriores.\n",
    "5. Repetição do processo.\n",
    "6. Avaliação final em dados de teste.\n",
    "\n",
    "## Técnicas usadas:\n",
    "\n",
    "* Busca aleatória\n",
    "* Otimização Bayesiana\n",
    "* Algoritmos genéticos\n",
    "* Outros métodos sem gradiente\n",
    "\n",
    "## Desafios:\n",
    "\n",
    "* Espaço de busca não é contínuo → sem gradiente\n",
    "* Cada avaliação é cara (novo modelo, novo treino).\n",
    "* Resultados podem ser ruidosos.\n",
    "\n",
    "> Otimizar o espaço de busca certo é essencial. Hiperparâmetro tuning **não substitui** conhecimento de boas práticas de modelagem.\n",
    "\n",
    "## Ferramentas úteis:\n",
    "\n",
    "* **KerasTuner**: oferece modelos tunáveis prontos (ex: `HyperXception`, `HyperResNet`)\n",
    "* **AutoML**: tenta automatizar *todo* o processo (ex: AutoKeras)\n",
    "\n",
    "# O que é ensembling?\n",
    "\n",
    "* Combina as previsões de vários modelos para melhorar o desempenho.\n",
    "* Cada modelo capta uma parte da verdade, juntos, os modelos enxergam o \"todo\" de forma mais precisa.\n",
    "\n",
    "## Técnicas comuns:\n",
    "\n",
    "* Média das previsões\n",
    "* Média ponderada (pesos ajustados pela validação)\n",
    "\n",
    "## Ponto-chave: **diversidade**\n",
    "\n",
    "* Quanto mais **diferentes** forem os modelos, melhor.\n",
    "* Modelos iguais com inicializações aleatórias = pouca diversidade → pouco ganho.\n",
    "\n",
    "## O que funciona bem:\n",
    "\n",
    "* Arquiteturas distintas\n",
    "* Diferentes abordagens (ex: redes neurais + árvores de decisão)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
