{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a59728",
   "metadata": {},
   "source": [
    "# **O que é *Text Generation*?**\n",
    "\n",
    "*Text generation* (geração de texto) é quando uma IA aprende a escrever sozinha, **prevendo a próxima palavra ou letra** com base no que já foi escrito antes.\n",
    "O Keras usa redes neurais, principalmente **LSTM** ou **GRU**, que são modelos bons pra lidar com **sequências**, como frases ou músicas.\n",
    "\n",
    "### Como funciona o processo:\n",
    "\n",
    "1. **Treinamento**: Você mostra muitos textos pra rede (livros, tweets, etc.).\n",
    "2. A rede aprende a **prever o que vem depois** em uma frase.\n",
    "3. Depois do treino, ela consegue **gerar frases novas**, letra por letra ou palavra por palavra.\n",
    "\n",
    "### Como a IA decide a próxima palavra?\n",
    "\n",
    "A rede gera uma **lista de probabilidades** para as próximas palavras possíveis.\n",
    "\n",
    "#### Exemplo:\n",
    "\n",
    "Se a frase for:\n",
    "\n",
    "> \"Hoje o céu está\"\n",
    "\n",
    "O modelo pode achar que:\n",
    "\n",
    "* “azul” tem 60% de chance\n",
    "* “nublado” tem 30%\n",
    "* “verde” tem 10%\n",
    "\n",
    "A pergunta é: **como escolher uma palavra a partir dessas chances?**\n",
    "Você pode:\n",
    "\n",
    "* Escolher a mais provável (mais certinha, mas repetitiva)\n",
    "* Escolher com sorte, usando uma **temperatura** (mais criativo e inesperado)\n",
    "\n",
    "### O que é temperatura?\n",
    "\n",
    "Temperatura controla o **nível de criatividade** da IA:\n",
    "\n",
    "* **Temperatura baixa (ex: 0.2)** → textos seguros e previsíveis\n",
    "* **Temperatura alta (ex: 1.5)** → textos criativos e até doidos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b92dc",
   "metadata": {},
   "source": [
    "### Estratégias de amostragem (sampling strategies)\n",
    "\n",
    "#### 1. **Greedy sampling** (escolha gananciosa)\n",
    "\n",
    "* Sempre escolhe **a palavra mais provável**.\n",
    "* Resultado: frases **repetitivas, chatas** e previsíveis.\n",
    "\n",
    "> \"Hoje o céu está azul. O céu está azul. O céu está azul...\"\n",
    "\n",
    "\n",
    "#### 2. **Stochastic sampling** (escolha aleatória com probabilidade)\n",
    "\n",
    "* Escolhe uma palavra **com base nas probabilidades**, mas com um toque de sorte.\n",
    "* Se “azul” tem 60%, “nublado” 30%, “verde” 10%... pode acabar saindo “nublado” ou até “verde” às vezes!\n",
    "* Resultado: frases **mais variadas e criativas**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7935f3c",
   "metadata": {},
   "source": [
    "# **1. Neural Style Transfer (NST)**\n",
    "\n",
    "**O que é?**\n",
    "É uma técnica onde você pega **o conteúdo de uma imagem** (tipo uma foto pessoal) e **o estilo de outra imagem** (tipo uma pintura do Van Gogh) e **mistura os dois**. O resultado é sua foto como se tivesse sido pintada pelo Van Gogh.\n",
    "\n",
    "### **Como funciona:**\n",
    "\n",
    "* A gente usa uma **rede neural treinada**, geralmente a **VGG19**, que já entende bem o que é textura, bordas, formas, etc.\n",
    "\n",
    "* A imagem final é uma que:\n",
    "\n",
    "  * **Parece com a imagem de conteúdo**\n",
    "  * **Tem o estilo da imagem de estilo**\n",
    "\n",
    "### **As Loss (funções de perda)**:\n",
    "\n",
    "1. **Content Loss (Perda de conteúdo):**\n",
    "\n",
    "   * Mede **o quanto a imagem final se parece com a imagem original (de conteúdo)**.\n",
    "   * Ela compara as ativações de camadas mais profundas (que capturam **formas** e **estruturas** da imagem).\n",
    "\n",
    "2. **Style Loss (Perda de estilo):**\n",
    "\n",
    "   * Mede **o quanto a imagem final tem o mesmo estilo (textura, cores, padrões)** da imagem de estilo.\n",
    "   * Isso é feito usando uma matriz chamada **Gram Matrix**, que mostra **quais padrões aparecem juntos nas camadas da rede** (tipo padrões de pinceladas).\n",
    "\n",
    "3. **Total Variation Loss (opcional):**\n",
    "\n",
    "   * Serve pra deixar a imagem mais **suave**, menos cheia de \"ruído\" ou pontinhos esquisitos.\n",
    "\n",
    "\n",
    "### **O que a rede faz?**\n",
    "\n",
    "Ela começa com uma imagem **aleatória** (ou a própria imagem de conteúdo) e **vai ajustando os pixels** dessa imagem pra **minimizar as perdas (losses)** acima, até a mistura ficar boa.\n",
    "\n",
    "\n",
    "# **2. Deep Dream**\n",
    "\n",
    "**O que é?**\n",
    "É uma técnica que pega uma imagem e \"força\" a rede neural a **ver padrões que ela aprendeu**, tipo transformar uma nuvem numa cachorrinha psicodélica.\n",
    "\n",
    "### **Como funciona:**\n",
    "\n",
    "* Usa uma rede neural treinada (tipo a Inception) e **pega uma imagem qualquer**.\n",
    "* Escolhe uma camada da rede e fala: \"**faz essa imagem ativar mais os neurônios dessa camada**\".\n",
    "* A imagem é **modificada pra realçar os padrões que essa camada gosta** — e aí aparecem aqueles efeitos meio \"alucinógenos\".\n",
    "\n",
    "\n",
    "### **Loss aqui:**\n",
    "\n",
    "* Ao contrário do NST, a loss aqui é **maximizar a ativação de certos neurônios da rede**.\n",
    "* Em vez de aprender, a rede está **“sonhando”**: reforçando o que ela já viu muito nos dados de treino.\n",
    "\n",
    "\n",
    "### **Resumo prático:**\n",
    "\n",
    "| Técnica               | Objetivo                   | Loss principal                               |\n",
    "| --------------------- | -------------------------- | -------------------------------------------- |\n",
    "| Neural Style Transfer | Misturar conteúdo + estilo | Content Loss + Style Loss (Gram Matrix)      |\n",
    "| Deep Dream            | Amplificar padrões da rede | Maximizar ativações de neurônios específicos |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60261171",
   "metadata": {},
   "source": [
    "# **O que é um Latent Space (espaço latente)?**\n",
    "\n",
    "Imagina que você quer guardar uma imagem (tipo a foto de um gato) **de forma bem resumida**.\n",
    "Ao invés de guardar todos os pixels da imagem, você transforma ela em **um vetor com alguns números**, tipo:\n",
    "\n",
    "```\n",
    "[0.4, -1.2, 3.7, 0.8, -0.5]\n",
    "```\n",
    "\n",
    "Esse vetor **representa as características principais da imagem**, tipo:\n",
    "\n",
    "* tem orelha pontuda?\n",
    "* tem pelo claro ou escuro?\n",
    "* o bicho tá de frente ou de lado?\n",
    "\n",
    "Chamamos esse **resumo em forma de vetor** de **representação latente**.\n",
    "\n",
    "O **Latent Space** é o **\"mapa\" de todos esses vetores possíveis**, que representam imagens diferentes.\n",
    "Se andar um pouco nesse mapa, pode sair de um \"gato\" pra um \"leão\", depois pra um \"cachorro\", por exemplo.\n",
    "\n",
    "# GAN = **Gerador + Discriminador**\n",
    "\n",
    "* O **Gerador** não vê imagens reais. Ele **pega um vetor aleatório** do **latent space** e tenta **gerar uma imagem realista** com base nele.\n",
    "* O **Discriminador** vê imagens reais e imagens falsas (do gerador) e tenta dizer quais são verdadeiras e quais são inventadas.\n",
    "\n",
    "**O jogo:**\n",
    "\n",
    "* O **gerador tenta enganar o discriminador** com imagens cada vez mais realistas.\n",
    "* O **discriminador tenta não ser enganado**.\n",
    "\n",
    "Com o tempo, o **gerador aprende a transformar vetores do latent space em imagens super realistas**.\n",
    "\n",
    "\n",
    "## **Diferença GAN vs VAE (Variação Importante)**\n",
    "\n",
    "* **VAE (Autoencoder Variacional)**: aprende um espaço latente **mais organizado**. É bom pra **editar imagens** mudando esses vetores com controle (tipo deixar a pessoa mais sorridente).\n",
    "* **GAN**: foca em realismo. Faz imagens lindas, mas o espaço latente pode ser **bagunçado**, então é **mais difícil de controlar** (tipo editar uma imagem específica).\n",
    "\n",
    "\n",
    "## **E por que GAN é difícil de treinar?**\n",
    "\n",
    "* Porque não tem uma única função de erro simples.\n",
    "* É uma briga entre duas redes: **o gerador quer enganar**, e o **discriminador quer descobrir**.\n",
    "* Isso torna o treinamento instável e cheio de ajustes manuais (os tais \"heuristic tricks\").\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
