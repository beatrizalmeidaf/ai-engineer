{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae6c1f8",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e58d4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353be135",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "Essa CNN é projetada para tarefas de classificação de imagens, onde a rede aprende a identificar padrões visuais (como bordas, formas e texturas) e, no final, classifica a imagem em uma das categorias possíveis (`num_classes`).\n",
    "\n",
    "---\n",
    "\n",
    "### Estrutura da Rede\n",
    "\n",
    "#### 1. `nn.Conv2d`\n",
    "Aplica filtros (ou kernels) nas imagens de entrada para detectar padrões como bordas, texturas, formas, etc.\n",
    "\n",
    "**Parâmetros principais:**\n",
    "- `in_channels=3`: número de canais da imagem de entrada (ex: 3 para RGB).\n",
    "- `out_channels=64`: número de filtros que serão aprendidos — a rede irá gerar 64 \"imagens\" diferentes com padrões distintos.\n",
    "- `kernel_size=11`: tamanho de cada filtro (nesse caso, 11x11).\n",
    "- `stride=4`: quanto o filtro \"anda\" na imagem a cada passo. Um valor maior reduz mais rapidamente o tamanho da imagem.\n",
    "- `padding=2`: adiciona bordas com zeros ao redor da imagem para preservar mais informações nas bordas.\n",
    "\n",
    "#### 2. `nn.ReLU`\n",
    "Aplica a função de ativação ReLU, que ajuda a rede a aprender relações não lineares (ou seja, mais complexas) entre os dados.\n",
    "\n",
    "#### 3. `nn.MaxPool2d`\n",
    "Reduz o tamanho da imagem (\"compressa\" a informação) pegando os valores mais altos de regiões locais. Isso ajuda a manter só as informações mais relevantes.\n",
    "\n",
    "---\n",
    "\n",
    "### Bloco `features`\n",
    "Essa sequência aplica várias camadas de convolução, ativação e pooling. A ideia é:\n",
    "- Aprender padrões simples nas primeiras camadas (ex: bordas, cores).\n",
    "- Evoluir para padrões mais complexos nas camadas seguintes (ex: partes de objetos, rostos, etc).\n",
    "\n",
    "---\n",
    "\n",
    "### Camada `avgpool`\n",
    "\n",
    "Reduz a imagem para um tamanho fixo (6x6), independente do tamanho que ela tinha antes. Isso é essencial para a etapa seguinte (camadas densas), que exige entrada de tamanho fixo.\n",
    "\n",
    "---\n",
    "\n",
    "### Camada `classifier`\n",
    "Responsável pela classificação final com base nas características extraídas.\n",
    "\n",
    "- Transforma os dados em um vetor de uma dimensão.\n",
    "- Passa por camadas densas (`Linear`) com ReLU e Dropout.\n",
    "- A última camada gera a saída com o número de classes desejado.\n",
    "\n",
    "---\n",
    "\n",
    "### Método `forward`\n",
    "Esse método define o fluxo de dados pela rede:\n",
    "1. Extração de características (features).\n",
    "2. Redução de tamanho (avgpool).\n",
    "3. Transformação em vetor (flatten).\n",
    "4. Classificação final (classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c6a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "    def __init__(self, num_classes=2): # construtor que monta a rede\n",
    "        super(CNNNet, self).__init__() # faz com que a classe funcione como um modulo do pytorch, ativando as funções internas dele\n",
    "        self.features == nn.Sequential(nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.MaxPool2d(kernel_size=3, stride=2), # diminui o tamanho da imagem e mantém só as informações mais fortes\n",
    "                                       nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                                       nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.MaxPool2d(kernel_size=3, stride=2),)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6,6)) # reduz o tamanho da imagem para um tamanho fixo: (6,6), independente de como ela chegou até aqui \n",
    "        # porque para a etapa de classificação a rede precisa de um tamanho fixo para funcionar\n",
    "        self.classifier = nn.Sequential(\n",
    "                          nn.Dropout(), # desliga aleatoriamente alguns neuronios durante o treino para evitar overfitting\n",
    "                          nn.Linear(256 * 6 * 6, 4096), # entrada densa conectada com entrada de 9216 valores e 4096 neuronios\n",
    "                          nn.ReLU(),\n",
    "                          nn.Dropout(),\n",
    "                          nn.Linear(4096, 4096),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(4096, num_classes)\n",
    "                            )\n",
    "\n",
    "    def forward(self, x):\n",
    "         x = self.features(x)\n",
    "         x = self.avgpool(x)\n",
    "         x = torch.flatten(x, 1) # transforma tudo em um só vetor\n",
    "         x = self.classifier(x)\n",
    "         return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
